\documentclass[handout,xcolor=pdftex,dvipsnames,table]{beamer} % for handouts
%\documentclass{beamer}

\usecolortheme[RGB={0,0,144}]{structure}
\usetheme{AnnArbor}\usecolortheme{beaver}
%\usetheme{CambridgeUS}\usecolortheme{crane}

\usepackage{verbatim,xmpmulti,color,multicol,multirow}
\setlength{\unitlength}{\textwidth}  % measure in textwidths
\usepackage[normalem]{ulem}

%\usepackage{beamerthemesplit}
\setbeamertemplate{navigation symbols}{}
%\setbeamercolor{alerted text}{fg=red}
%\setbeamertemplate{block body theorem}{bg=orange}
\setkeys{Gin}{width=0.6\textwidth}

\title{Bayesian hypothesis testing}
\author[Jarad Niemi]{Dr. Jarad Niemi}
\institute[Iowa State]{Iowa State University}
\date{\today}

\begin{document}

%\section{Temp??} \begin{comment}

<<chunk_options, echo=FALSE>>=
opts_chunk$set(fig.width=6, fig.height=5, out.width='.8\\linewidth', fig.align='center', size='tiny')
####################################
# L6 - Bayesian hypothesis testing #
####################################
library(reshape2)
library(plyr)
library(ggplot2)
@

\frame{\titlepage}
\section{Testing}
\frame{\frametitle{Scientific method}
  \begin{center}
  \includegraphics{screenshot_3_29_13_5_50_pm}
  \end{center}
  
{\tiny \url{http://www.wired.com/wiredscience/2013/04/whats-wrong-with-the-scientific-method/}}
}

\section{Likelihood Ratio Tests}
\frame{\frametitle{Likelihood Ratio Tests}
  Consider a likelihood $L(\theta|y)= p(y|\theta)$, then the liklihood ratio test statistic for testing $H_0:\theta\in \Theta_0$ and $H_1: \theta\in \Theta_0^c$ \pause with $\Theta = \Theta_0\cup \Theta_0^c$ is 
  \[ \lambda(y) = \frac{\mbox{sup}_{\Theta_0} L(\theta|y)}{\mbox{sup} _{\Theta} L(\theta|y)} \pause = \frac{L(\hat{\theta_0}_{MLE}|y)}{L(\hat{\theta}_{MLE}|y)} \]
  \pause where $\hat{\theta}_{MLE}$ and $\hat{\theta_0}_{MLE}$ are the (restricted) MLEs. \pause The likelihood ratio test (LRT) is any test that has a rejection region of the form $\{ y: \lambda(y)\le c\}$. (Casella \& Berger Def 8.2.1)
  
  \vspace{0.2in} \pause 
  
  Under certain conditions (see Casella \& Berger 10.3.3), as $n\to \infty$ 
  \[ -2\log \lambda(y) \to \chi^2_{\nu} \]
  \pause where $\nu$ us the difference between the number of free parameters specified by $\theta\in\theta_0$ and the number of free parameters specified by $\theta\in \Theta$. 
}



\subsection{Binomial example}
\frame{\frametitle{Binomial example}
  Consider a coin flipping experiment so that $Y_i \stackrel{iid}{\sim} Ber(\theta)$ and the null hypothesis $H_0:\theta=0.5$ versus the alternative $H_1:\theta\ne 0.5$. \pause Then 
  \[  
  \lambda(y) = \frac{\mbox{sup} _{\Theta_0} L(\theta|y)}{\mbox{sup} _{\Theta} L(\theta|y)}= \frac{0.5^n}{\hat{\theta}_{MLE}^{n\overline{y}}(1-\hat{\theta}_{MLE})^{n-n\overline{y}}}  = \frac{0.5^n}{\overline{y}^{n\overline{y}}(1-\overline{y})^{n-n\overline{y}}} 
   \]
   \pause and 
   $-2\log \lambda(y) \to \chi^2_1$ as $n\to\infty$ so 
   \[ pvalue \approx P(\chi^2_1>-2\log \lambda(y)). \]
   \pause If $pvalue < \alpha$, then we reject $H_0$ at level $\alpha$. \pause Typically $\alpha=0.05$. 
}

\begin{frame}[fragile]
\frametitle{Binomial example}
<<lrt_binomial,fig.width=8, warning=FALSE>>=
d = expand.grid(n=seq(10,30,by=10), ybar=seq(0,1,by=0.01))
lrt = function(n,ybar) exp(n*log(0.5)-n*ybar*log(ybar)-n*(1-ybar)*log(1-ybar))
pvalue = function(lrt,df=1) 1-pchisq(-2*log(lrt),df)
d = ddply(d,.(n,ybar), summarize, lrt = lrt(n,ybar))
p_lrt = ggplot(d, aes(x=ybar, y=pvalue(lrt,1), col=factor(n)))+geom_line()+labs(y="pvalue")+geom_abline(intercept=0.05,slope=0,col="gray")
print(p_lrt)
@
\end{frame}


\section{Bayesian hypothesis testing}
\frame{\frametitle{Bayesian hypothesis testing}
  Consider a statistical model $p(y|\theta)$, a hypothesis $H_0: \theta\in \Theta_0$ \alert{with prior $p(\theta|H_0)$}, and $H_1:\theta\in \Theta_0^c$ \alert{with prior $p(\theta|H_1)$}, \pause then the Bayes factor for comparing $H_0$ to $H_1$ is 
  \[ BF(H_0:H_1) = \frac{p(y|H_0)}{p(y|H_1)} \pause = \frac{\int_{\Theta_0} p(y|\theta)\alert{p(\theta|H_0)} d\theta}{\int_{\Theta_0^c} p(y|\theta)\alert{p(\theta|H_1)} d\theta}.  \]
  \pause A decision is based on the posterior model probability, i.e. 
  \[ p(H_1|y) = \frac{p(y|H_1)p(H_1)}{p(y|H_1)p(H_1)+p(y|H_0)p(H_0)} \pause = \frac{1}{1+BF(H_0:H_1) \alert{\frac{p(H_0)}{p(H_1)}}}. \]
  \pause Typically if $p(H_1|y)>0.5$, we would prefer $H_1$.

}

\subsection{Binomial model}
\frame{\frametitle{Binomial model}
  Consider a coin flipping experiment so that $Y_i \stackrel{iid}{\sim} Ber(\theta)$ and the null hypothesis $H_0:\theta=0.5$ versus the alternative $H_1:\theta\ne 0.5$ with prior $Be(a,b)$. 
  \[ \begin{array}{rl}
  BF(H_0:H_1) &= \frac{0.5^n}{\int_0^1 \theta^{n\overline{y}}(1-\theta)^{n(1-\overline{y})} \frac{\theta^{a-1}(1-\theta)^{b-1}}{Be(a,b)} d\theta } \\
  &= \frac{0.5^n}{\frac{1}{Be(a,b)} \int_0^1 \theta^{a+n\overline{y}-1}(1-\theta)^{b+n-n\overline{y}-1} \theta}\\
  &= 0.5^n \left/ \frac{Be(a+n\overline{y},b+n-n\overline{y})}{Be(a,b)} \right.
  \end{array} \]
  \pause and with $p(H_0)=p(H_1)$ the posterior model probability is 
    \[ P(H_0|y) = \frac{1}{1+1/BF(H_0:H_1)} \]
    since $BF(H_1:H_0) = 1/BF(H_0:H1)$.
}

\begin{frame}[fragile]
\frametitle{Binomial model}
<<posterior_binomial, fig.width=8>>=
bf = function(n,ybar,a=1,b=1) exp(n*log(0.5)+lbeta(a,b)-lbeta(a+n*ybar,b+n-n*ybar))
d = ddply(d, .(n,ybar), summarize, bf=bf(n,ybar))
post_prob = function(bf, prior_odds=0.5) 1/(1+1/bf*prior_odds)
p_bayes = ggplot(d, aes(x=ybar, y=post_prob(bf), color=factor(n))) + geom_line() 
print(p_bayes+ylim(0,1))
@
\end{frame}




\section{Jeffrey-Lindley paradox}
\begin{frame}
\frametitle{Do pvalues and posterior probabilities agree?}
Suppose $n=10,000$ and $y=4,900$, \pause then the pvalue is 
\[ pvalue \approx P(\chi^2_1>-2 \log(0.135)) = 0.045 \]
\pause so we would reject $H_0$ at the 0.05 level. 

\vspace{0.2in} \pause

The posterior probability of $H_0$ is 
\[ p(H_0|y) \approx \frac{1}{1+1/10.8} = 0.96, \]
\pause so the probability of $H_0$ being true is 96\%. 

\vspace{0.2in} \pause 

It appears the Bayesian and LRT pvalue completely disagree!
\end{frame}

\begin{frame}[fragile]
\frametitle{Binomial $\overline{y}=0.49$ with $n\to\infty$} 
<<paradox,fig.width=8>>=
paradox = expand.grid(n=10^(seq(0,5,by=0.1)), ybar=0.49)
paradox = ddply(paradox, .(n,ybar), summarize, pvalue=pvalue(lrt(n,ybar)), post_prob=post_prob(bf(n,ybar)))
m = melt(paradox, id=c("n","ybar"))
p = ggplot(m, aes(log10(n),value,col=variable))+geom_line() 
print(p)
@
\end{frame}

\subsection{Jeffrey-Lindley Paradox}
\frame{\frametitle{Jeffrey-Lindley Paradox}
  \begin{definition}
  The \alert{Jeffrey-Lindley Paradox} concerns a situation when comparing two hypotheses $H_0$ and $H_1$ given data $y$ \pause and find
  \begin{itemize}[<+->]\small
  \item a frequentist test result is significant leading to rejection of $H_0$, but
  \item the posterior probability of $H_0$ is high. 
  \end{itemize}
  \end{definition}
  
  \vspace{0.2in} \pause
  
  This can happen when 
  \begin{itemize}[<+->]\small
  \item the effect size is small, 
  \item $n$ is large, 
  \item $H_0$ is relatively precise, 
  \item $H_1$ is relative diffuse, and
  \item the prior model odds is $\approx 1$. 
  \end{itemize}
}

\frame{\frametitle{Comparison}
  The test statistic with point null hypotheses:
  \[ \begin{array}{rl}
  \lambda(y) &= \frac{ p\left(y|\theta_0\right)}{p\left(y|\hat{\theta}_{MLE}\right)} \\ \\
  BF(H_0:H_1) &= \frac{ p\left(y|\theta_0\right)}{\int p(y|\theta)p(\theta|H_1) d\theta} \uncover<6->{= \frac{p(y|H_0)}{p(y|H_1)}}
  \end{array} \]
  \pause 
  
  A few comments:
  \begin{itemize}[<+->]\small
  \item The LRT chooses the best possible alternative value. 
  \item The Bayesian test penalizes for vagueness in the prior.
  \item The LRT can be interpreted as a Bayesian point mass prior exactly at the MLE. 
  \item Generally, pvalues provide a measure of lack-of-fit of the null model. 
  \item Bayesian tests compare predictive performance of two Bayesian models (model+prior). 
  \end{itemize}
}

\section{Priors for hypothesis testing}
\frame{\frametitle{Priors for hypothesis testing}
  Consider the model $Y\sim N(\theta,1)$ and the hypothesis test
  \begin{itemize}[<+->]
  \item $H_0: \theta=0$ versus
  \item $H_1: \theta\ne 0$ with prior $\theta|H_1 \sim N(0,A)$.
  \end{itemize}
  
  \vspace{0.2in} \pause 
  
  The predictive distribution under $H_1$ is \pause
  \[ p(y|H_1) = \int p(y|\theta) p(\theta|H_1) d\theta \pause = N(y;0,1+A) \]
  \pause and the Bayes factor is 
  
  \[ BF(H_0:H_1) = \frac{N(y;0,1)}{N(y;0,1+A)}. \]
  \pause The Bayes factor will decrease as $A\to \infty$ for any $y$ \pause and this only gets worse if you use an improper prior.
}

\begin{frame}[fragile]
\frametitle{}
<<normal_bayes_factor, fig.width=8>>=
d = ddply(expand.grid(y=seq(0,5,by=.1), A=10^(0:4)), .(y,A), summarize,
          post_prob_H0 = 1/(1+1/exp(dnorm(y,0,1,log=TRUE)-dnorm(y,0,1+A,log=TRUE))))
p = ggplot(d, aes(y, post_prob_H0, color=factor(A)))+geom_line()
print(p)
@
\end{frame}


\section{Composite hypotheses}
\frame{\frametitle{Prior probabilities on point null hypotheses}
  What is your prior probability for the following situations:
  \begin{itemize}[<+->] \small
  \item a coin flip has exactly 0.5 probability of landing heads
  \item a fertilizer treatment has zero effect on plant growth
  \item inactivation of a mouse growth gene has zero effect on mouse hair color
  \item a butterfly flapping its wings in Australia has no effect on temperature in Ames
  \item guessing the color of a card drawn from a deck has probability 0.5
  \end{itemize}
  
  \vspace{0.2in} \pause 
  
  Many null hypotheses have zero probability \emph{a priori}, so why bother performing the hypothesis test?
}

\frame{\frametitle{Composite hypotheses}
  Consider the model $Y\sim p(y|\theta)$ and the hypothesis test
  \begin{itemize}[<+->]
  \item $H_0: \theta<\theta_0$ versus
  \item $H_1: \theta\ge \theta_0$.
  \end{itemize}
  
  \vspace{0.2in} \pause
  
  We could 
  \begin{itemize}[<+->]
  \item assign a prior for $\theta$ under $H_0$, 
  \item assign a prior for $\theta$ under $H_1$, and 
  \item assign a prior probabiity for the hypotheses $P(H_0)=1-P(H_1)$. 
  \end{itemize}
  
  \vspace{0.2in} \pause 
  
  It seems much easier to just assume a single prior $p(\theta)$ and calculate 
  \begin{itemize}
  \item $P(\theta>\theta_0|y)=1-P(\theta\le \theta_0|y)$. 
  \end{itemize}
  \pause This is actually the approach suggested by Casella \& Berger (Section 8.2.2), but it doesn't work for point hypotheses. 
}

\subsection{Binomial model}
\begin{frame}[fragile]
\frametitle{If $Y\sim Bin(n,\theta)$, what is $P(\theta>0.5)$?} 
<<binomial_composite, fig.width=14>>=
n = 10
y = 3
a = b = 1
d = data.frame(x=seq(0,1,by=0.01))
d$y = dbeta(d$x, a+y, b+n-y)
shade = rbind(c(0.5,0), d[d$x>=0.5,], c(1,0))
p = ggplot(d, aes(x,y)) + geom_line() + geom_polygon(data=shade, aes(x, y))
1-pbeta(0.5, a+y, b+n-y)
print(p)
@
\end{frame}

\section{Multiple point hypotheses}
\frame{\frametitle{Multiple point hypotheses}
  Suppose $y\sim p(y|\theta)$ and $H_i:\theta=\theta_i$ and $p(H_i)=p_i$ for $i=1,\ldots,\mathrm{I}$ with $\sum_{i=1}^\mathrm{I} p_i=1$. 
  
  \vspace{0.2in} \pause 
  
  Rather than consider this a hypothesis test, consider this an estimation using a discrete prior\pause, i.e. $p(\theta=\theta_i)=p_i$. \pause Then the posterior is 
  \[ p(\theta=\theta_i|y) = \frac{p_i p(y|\theta_i)}{\sum_{i=1}^\mathrm{I} p_i p(y|\theta_i)}. \]
  
  \vspace{0.2in} \pause
  
  This can be a computationally convenient way to use a complicated prior.
}

\begin{frame}[fragile]
\frametitle{}
<<crazy_prior, fig.width=10>>=
set.seed(1)
I = 100
theta = runif(I)
prior = runif(I); prior=prior/sum(prior)
post  = prior*dbeta(theta,a+y,b+n-y); post = post/sum(post)
d = data.frame(theta=theta,prior=prior,post=post)
m = melt(d, id="theta")
p = ggplot(m, aes(theta,value,col=variable))+geom_point() + stat_function(fun= function(x) dbeta(x,a+y, b+n-y)/I, col="gray")
print(p)
@
\end{frame}

\section{Summary}
\frame{\frametitle{Summary}
  \begin{itemize}[<+->] \small
  \item Bayesian hypothesis testing requires no asymptotics.
  \item Bayesian hypothesis testing can easily handle more than 2 hypotheses.
  \item The prior predictive distribution can often be hard to analytically evaluate.

  \vspace{0.2in} 
  
  \item From a Bayesian perspective, most point null hypotheses have probability zero.
  \item Bayesian hypothesis testing is really looking at (prior) predictive performance of the models.
  \item These predictions require reasonable proper priors.  
  
  \vspace{0.2in} 
  
  \item When all hypotheses are composite, prefer estimation.
  \item When all hypotheses are point null, prefer estimation with a discrete prior. 
  \end{itemize}
}

\section{Testing}
\frame{\frametitle{Scientific method updated}
  \begin{quote}
  All models are wrong, but some are useful.
  \end{quote}
  George Box 1987 \pause 

  \begin{center}
  \includegraphics{screenshot_3_30_13_3_32_pm}
  \end{center}
  
{\tiny \url{http://www.wired.com/wiredscience/2013/04/whats-wrong-with-the-scientific-method/}}
}

\end{document}
