\documentclass{beamer}
%\documentclass[handout,xcolor=pdftex,dvipsnames,table]{beamer} % for handouts


\usecolortheme[RGB={0,0,144}]{structure}
\usetheme{AnnArbor}\usecolortheme{beaver}
%\usetheme{CambridgeUS}\usecolortheme{crane}

\usepackage{verbatim,xmpmulti,color,multicol,multirow}
\setlength{\unitlength}{\textwidth}  % measure in textwidths
\usepackage[normalem]{ulem}

%\usepackage{beamerthemesplit}
\setbeamertemplate{navigation symbols}{}
%\setbeamercolor{alerted text}{fg=red}
%\setbeamertemplate{block body theorem}{bg=orange}
\setkeys{Gin}{width=0.6\textwidth}

\title[Markov chain theory]{Discrete-time, discrete-space Markov chain theory}
\author[Jarad Niemi]{Dr. Jarad Niemi}
\institute[Iowa State]{Iowa State University}
\date{\today}

\newcommand{\I}{\mathrm{I}}

\begin{document}

%\section{Temp??} \begin{comment}

<<chunk_options, echo=FALSE, message=FALSE>>=
library(knitr) # only needed so the following command does not fail when sourcing R code
opts_chunk$set(fig.width=6, fig.height=5, out.width='.8\\linewidth', fig.align='center', size='tiny')
##############################################
# Markov chain theory                        #
##############################################
library(reshape2)
library(plyr)
library(ggplot2)
library(rjags)
set.seed(1)
@

\frame{\maketitle}

\section{Markov chain theory}
\begin{frame}
\frametitle{Markov chains}

\begin{definition}
A \alert{discrete-time, time-homogeneous Markov chain} is a sequence of random variables $\theta^t$ \pause such that
\[ p(\theta^t|\theta^{t-1},\ldots,\theta^0) = p(\theta^t|\theta^{t-1}) \]
\pause which is known as the \alert{transition distribution}.
\end{definition}

\pause 

\begin{definition}
The \alert{state space} is the support of the Markov chain.
\end{definition}

\pause 

\begin{definition}
The transition distribution of a Markov chain whose state space is discrete \pause can be represented with a  \alert{transition matrix} $P$ \pause with elements $P_{ij}$ representing the probability of moving from state $i$ to state $j$ in one time-step. 
\end{definition}
\end{frame}





\subsection{Correlated coin flip}
\begin{frame}
\frametitle{Correlated coin flip}
Let 
\[ P = \bordermatrix{ & 0 & 1 \cr 0 & 1-p & p \cr 1 & q & 1-q } \]
\pause where 
\begin{itemize}[<+->]
\item the state space is $\{0,1\}$, 
\item $p$ is the probability of switching from 0 to 1, and 
\item $q$ is the probability of switching from 1 to 0.
\end{itemize}
\end{frame}


\begin{frame}[fragile]
<<correlted_coin_flip, fig.width=10>>=
rflip = function(n, p, q, theta0) {
  theta = rep(theta0, n+1)
  for (i in 1:n) theta[i+1] = ifelse(theta[i], rbinom(1,1,1-q), rbinom(1,1,p))
  theta
}
set.seed(1)
n = 100
qplot(0:n, rflip(n,p <- .2,q <- .4, rbinom(1,1,.5)))+labs(x="Time",y="State",title="Correlated coin flip")
@
\end{frame}


\subsection{DNA sequence}
\begin{frame}
\frametitle{DNA sequence}
\[ P = \bordermatrix{ & A & C & G & T \cr 
A & 0.60 & 0.10 & 0.10 & 0.20 \cr 
C & 0.10 & 0.50 & 0.30 & 0.10 \cr
G & 0.05 & 0.20 & 0.70 & 0.05 \cr
T & 0.40 & 0.05 & 0.05 & 0.50 } \]
\pause where 
\begin{itemize}
\item with state space \{A,C,G,T\} \pause and
\item each cell provides the probability of moving from the row nucleotide to the column nucleotide. \pause
\end{itemize}

{\tiny \url{http://tata-box-blog.blogspot.com/2012/04/introduction-to-markov-chains-and.html}}
\end{frame}


\begin{frame}[fragile]
<<dna_seq, fig.width=12>>=
nucleotides = factor(c("A","C","G","T"))
dna_seq_m = matrix(rbind(c(.6,.1,.1,.2), c(.1,.5,.3,.1), c(.05,.2,.7,.05), c(.4,.05,.05,.5)),4)
r_dna_seq = function(n,theta0) {
  theta = rep(theta0,n+1)
  for (i in 1:n) theta[i+1] = sample(nucleotides,1,prob=dna_seq_m[as.numeric(theta[i]),])
  theta
}
(my_seq = r_dna_seq(n, sample(nucleotides,1)))
qplot(0:n,my_seq)+labs(x="Time",y="Nucleotide",main="Markov chain for a DNA sequence")
@
\end{frame}



\subsection{Random walk on the integers}
\begin{frame}
\frametitle{Random walk on the integers}
Let 
\[ 
P_{ij} = \left\{ \begin{array}{ll}
1/3 &\mbox j\in \{i-1,i,i+1\} \\
0 & \mbox{otherwise}
\end{array} \right.
\]
where 
\begin{itemize}
\item the state space is the integers, i.e. $\{\ldots,-1,0,1,\ldots\}$ \pause and 
\item the transition matrix $P$ is infinite-dimensional.
\end{itemize}
\end{frame}

\begin{frame}[fragile]
\frametitle{Random walk on the integers}
<<random_walk_on_the_integers, fig.width=12>>=
rwalk = function(n, theta0) {
  theta = rep(theta0, n+1)
  for (i in 1:n) theta[i+1] = sample(c(-1,0,1), 1)+theta[i]
  theta
}
qplot(0:n, rwalk(n, theta0=0))+labs(x="Time",y="State",title="Random walk on the integers")
@
\end{frame}







\subsection{Stationary distribution}
\begin{frame}
\frametitle{Stationary distribution}
\small
  Let $\pi^t$ denote a row vector with 
  \[ \pi_i^t = Pr(\theta^t=i). \]
  \pause Then 
  \[ \pi^t = \pi^{t-1} P. \]
  \pause Thus, $\pi^0$ and $P$ completely characterizes $\pi^t$. \pause 
  \begin{definition}
  The \alert{stationary distribution} is the distribution $\pi$ 
  \[ \pi = \pi P. \]
  
  \pause 
  
  This is also called the \alert{invariant} or \alert{equilibrium distribution}.
  \end{definition}

  \pause 
  
  Given a transition matrix $P$, \pause 
  \begin{itemize}
  \item Does a $\pi$ exist such that $\pi = \pi P$? \pause 
  \item If $\pi$ is unique, does $\lim_{t\to\infty} \pi^t = \pi$ for all $\pi^0$? \pause In this case, $\pi$ is often called the \alert{limiting distribution}.
  \end{itemize}

\end{frame}




\begin{frame}
\frametitle{Stationary distribution exists, but is not unique}

Let 
\[ P = \bordermatrix{ & 0 & 1 \cr 0 & 1 & 0 \cr 1 & 0 & 1 } \]
\pause then 
\[ \pi = \pi P \]
for any $\pi$. 

\vspace{0.2in} \pause 

This Markov chain stays where it is.

\end{frame}








\subsection{Irreducibility}
\begin{frame}
\frametitle{Irreducibility}

\begin{definition}
A Markov chain is \alert{irreducible} if for all $i$ and $j$
\[ Pr(\theta^{t_{ij}}=j|\theta^0=i) > 0 \]
for some $t_{ij}\ge 0$.
\end{definition}
\pause 
Reducible example:
\[ P = \bordermatrix{ & 0 & 1 & 2 & 3  \cr 
0 & 0.5 & 0.5 & 0 & 0 \cr
1 & 0.5 & 0.5 & 0 & 0 \cr
2 & 0 & 0 & 0.5 & 0.5 \cr
3 & 0 & 0 & 0.5 & 0.5 } \]
\end{frame}




\begin{frame}
\frametitle{Stationary distribution is unique, but is not the limiting distribution.}

Let 
\[ P = \bordermatrix{ & 0 & 1 \cr 0 & 0 & 1  \cr 1 & 1 & 0 } \]
\pause then $\pi=\left(\frac{1}{2}\,\,\frac{1}{2}\right)$ since $\pi=\pi P$\pause, but
\[ \lim_{t\to\infty} \pi^t \ne \pi \,\forall\, \pi^0\]
\pause since 

\[ 
\pi^t = 
\left\{ \begin{array}{rll}
\pi^0 & t\mbox{ even} \pause \\
1-\pi^0 & t\mbox{ odd}
\end{array} \right. \]

\vspace{0.2in} \pause 

This Markov chain jumps back and forth.

\end{frame}





\subsection{Aperiodic}
\begin{frame}\frametitle{Aperiodic}

\begin{definition}
The \alert{period} $k_i$ of a state $i$ is 
\[ k_i = \mbox{gcd}\{t: Pr(\theta^t=i|\theta^0=i)>0\}\]
where gcd is the greatest common divisor. \pause If $k_i=1$, then state $i$ is said to be \alert{aperiodic}\pause, i.e.
\[ Pr(\theta^{t'}=i|\theta^0=i)>0 \]
for $t'>t$ for some $t$. \pause A Markov chain is \alert{aperiodic} if every state is aperiodic.
\end{definition}

\pause 
Period example:
\[ P = \bordermatrix{ & 0 & 1 & 2 & 3  \cr 
0 & 0 & 1 & 0 & 0 \cr
1 & 0 & 0 & 1 & 0 \cr
2 & 0 & 0 & 0 & 1 \cr
3 & 1 & 0 & 0 & 0 } \]

\end{frame}


\begin{frame}\frametitle{Example}
Let
\[ P = \left(
\begin{array}{cc}
0 & 1  \\
\frac{1}{2} & \frac{1}{2} 
\end{array}
\right) \]
\pause Note that 
\[ \begin{array}{rl}
Pr(\theta^1=0|\theta^0=0) &= \pause0 \pause  \\
Pr(\theta^2=0|\theta^0=0) &= \pause\frac{1}{2} \pause \\
Pr(\theta^3=0|\theta^0=0) &= \pause\frac{1}{2}\frac{1}{2} = \frac{1}{4} \pause \\
Pr(\theta^4=0|\theta^0=0) &= \pause\frac{1}{2}\frac{1}{2}+\frac{1}{2}\frac{1}{2}\frac{1}{2} = \frac{3}{8} \pause \\ 
\vdots
\end{array} \]
generally $Pr(\theta^t=0|\theta^0=0)>0$ for all $t>1$. \pause The \alert{period} $k$ of state 0 is 
\[ \mbox{gcd}\{t: Pr(\theta^t=i|\theta^0=i)>0\}\pause =\mbox{gcd}\{2,3,4,5,\ldots \}\pause =1 \]
\pause Thus state $0$ is aperiodic. \pause State $1$ is trivially aperiodic since $P(\theta^1=1|\theta^0=1)=1/2>0$. \pause Thus the Markov chain is aperiodic.

\end{frame}



\subsection{Finite support convergence}
\begin{frame}\frametitle{Finite support convergence}

\begin{lemma}
Every state in an irreducible Markov chain has the same period. Thus, in an irreducible Markov chain, if one state is aperiodic, then the Markov chain is aperiodic. 
\end{lemma}
\pause
\begin{theorem}
A \alert{finite} state space, \alert{irreducible} Markov chain has a unique stationary distribution $\pi$. If it is \alert{aperiodic}, then $\lim_{t\to\infty} \pi^t=\pi$ for all $\pi^0$.
\end{theorem}
\end{frame}




\begin{frame}
\frametitle{Correlated coin flips}
\small

For \[ P = \bordermatrix{ & 0 & 1 \cr 0 & 1-p & p \cr 1 & q & 1-q } \]
is irreducible and aperiodic if $0<p,q<1$\pause, thus the Markov chain with transition matrix $P$ has a unique stationary distribution and the chain converges to this distribution. 

\pause Since $\pi = \pi P$ and $\pi_0+\pi_1=1$, we have 

\[ \begin{array}{rl}
\pi_0 &= \pi_0(1-p)+\pi_1 q \pause \implies \\
\frac{p}{q} &= \frac{\pi_1}{\pi_0} \pause = \frac{\pi_1}{1-\pi_1} \pause \implies \\
\pi_1 &= \frac{p}{p+q} \pause \implies  \\
\pi_0 &= \frac{q}{p+q}
\end{array} \]
\pause 

So, the stationary distribution for $P$ is $\pi=(q,p)/(p+q)$.
\end{frame}



\begin{frame}[fragile]
\frametitle{Calculate numerically}

For finite state space and $P^t = P^{t-1} P$\pause, we have 
\[ \lim_{t\to\infty} \pi^t 
= \lim_{t\to\infty} \pi^0 P^t \pause
= \pi^0 \lim_{t\to\infty} P^t \pause 
= \pi^0 \left[ \begin{array}{c} \pi \\ \vdots \\ \pi \end{array} \right] \pause 
= \pi \pause  \]

<<P>>=
p = 0.2; q = 0.4
create_P = function(p,q) matrix(c(1-p,p,q,1-q), 2, byrow=TRUE)
P = Pt = create_P(p,q)
for (i in 1:100) Pt = Pt%*%P
Pt
c(q,p)/(p+q)
@

\end{frame}




\begin{frame}
\frametitle{Random walk on the integers}
Let 
\[ P_{ij} = \left\{ \begin{array}{ll} 
1/3 & j\in \{i-1,i,i+1\} \\
0 & \mbox{otherwise} \end{array} \right.. \]
\pause 

Then, this Markov chain is 
\begin{itemize}
\item irreducible 
\[ Pr(\theta^{|j-i|}=j|\theta^0=i) = 3^{-|j-i|}>0, \]

\item and aperiodic 
\[ Pr(\theta^t=i|\theta^{t-1}=i)=1/3, \]
\end{itemize}
but the Markov chain does not have a stationary distribution.

\vspace{0.2in} \pause

The Markov chain can wander off forever.

\end{frame}




\begin{frame}
\frametitle{}
\tiny 

A stationary distribution must satisfy $\pi=\pi P$ with 
\[ P = \left( \begin{array}{ccccccccc} 
&&&& \vdots &&&& \\
& 0 & 1/3 & 1/3 & 1/3 & 0 & 0 & 0 & \\
\cdots & 0 & 0 & 1/3 & 1/3 & 1/3 & 0 & 0 & \cdots \\
& 0 & 0 & 0 & 1/3 & 1/3 & 1/3 & 0 & \\
&&&& \vdots &&&& 
\end{array}  \right) \]
or, more succinctly, 
\[ \pi_i = \frac{1}{3}\pi_{i-1} +\frac{1}{3}\pi_{i} +\frac{1}{3}\pi_{i+1}. \]
Thus we must solve for $\{\pi_i \}$ that satisfy
\[ \begin{array}{rlrl}
2\pi_i &= \pi_{i-1}+\pi_{i+1} \,\forall\, i\\
\sum_{i=-\infty}^\infty \pi_i&=1 \\
\pi_i & \ge 0 \,\forall\, i
\end{array} \]
Note that 
\[ \begin{array}{rlrl}
\pi_2 &= 2\pi_1-\pi_0 \\
\pi_3 &= 2\pi_2-\pi_1 = 3\pi_1-2\pi_0 \\
\vdots \\
\pi_i &= i\pi_1-(i-1)\pi_0
\end{array} \]
Thus
\[ \begin{array}{rlrl}
\mbox{if } \pi_1=\pi_0>0, & \mbox{then }\pi_i=\pi_1, \,\forall\, i\ge 2\mbox{ and } \sum_{i=0}^\infty \pi_i > 1 \\
\mbox{if } \pi_1>\pi_0,   & \mbox{then } \pi_i \to  \infty \\
\mbox{if } \pi_1<\pi_0,   & \mbox{then } \pi_i \to -\infty \\
\mbox{if } \pi_1=\pi_0=0, & \mbox{then } \pi_i=0 \,\forall\, i\ge 0
\end{array} \]
But we also have $\pi_i = 2\pi_{i+1}-\pi_{i+2}$ so that 
\[ \begin{array}{rlrl}
\mbox{if } \pi_1=\pi_0=0, & \mbox{then } \pi_i=0 \,\forall\, i\le 0
\end{array} \]
Thus a stationary distribution does not exist.

\end{frame}




\subsection{Recurrence}

\begin{frame}

\frametitle{Recurrence}

\small

\begin{definition}
Let $T_i$ be the first return time to state $i$\pause, i.e.
\[ T_i =\mbox{inf}\{t\ge 1: \theta^t=i|\theta^0=i\} \]
\pause 
A state is \alert{recurrent} if $Pr(T_i<\infty)=1$ and is \alert{transient} otherwise. \pause A recurrent state is \alert{positive recurrent} if $E[T_i]<\infty$ and is \alert{null recurrent} otherwise. \pause A Markov chain is called \alert{positive recurrent} if all of its states are positive recurrent.
\end{definition}

\pause

\begin{lemma}
If a Markov chain is irreducible and one of its states is positive (null) recurrent, then all of its states are positive (null) recurrent.
\end{lemma}

\pause

\begin{lemma}
If state $i$ of a Markov chain is aperiodic, then $\lim_{t\to\infty} \pi^t_i = 1/E[T_i]$. 
\end{lemma}

\end{frame}






\begin{frame}

\frametitle{Stationarity and convergence}
\begin{theorem}
For an \alert{irreducible} and \alert{aperiodic} Markov chain, 
\begin{itemize}
\item if the Markov chain is \alert{positive recurrent}, then there exists a unique $\pi$ so that $\pi=\pi P$ and $\lim_{t\to\infty} \pi^t = \pi$ with $\pi_i=1/E[T_i]$, \pause
\item if there exists a positive vector $\pi$ such that $\pi=\pi P$ and $\sum_i \pi_i=1$, then it must be the stationary distribution and $\lim_{t\to\infty} \pi^t = \pi$, \pause and
\item if there exists a positive vector $\pi$ such that $\pi=\pi P$ and $\sum_i \pi_i$ is infinite, then a stationary distribution does not exist and $\lim_{t\to\infty} \pi^t_i=0$ for all $i$. 
\end{itemize}
\end{theorem}
\end{frame}




\begin{comment}
\subsection{AR1}
\begin{frame}
\frametitle{Autoregressive process of order 1}
With continuous support, the transition can be represented with a probability density function, e.g. 
\[ \theta^t|\theta^{t-1} \sim N(\mu+ \rho [\theta^{t-1}-\mu], \sigma^2). \]
\end{frame}

\begin{frame}[fragile]
<<autoregressive_process_1, fig.width=10>>=
rar1 = function(n, mu, rho, sigma, theta0) {
  theta = rep(theta0, n+1)
  for (i in 1:n) theta[i+1] = rnorm(1, mu+rho*(theta[i]-mu), sigma)
  theta
}
qplot(0:n, rar1(n, 0,.95,1,0), geom="point")
@
\end{frame}



\begin{frame}
\frametitle{Stationary distribution for AR1 process}

Let $\theta^t|\theta^{t-1} \sim N(\mu+\rho[\theta^{t-1}-\mu],\sigma^2)$, or, equivalently
\[ \theta^t = \mu+\rho[\theta^{t-1}-\mu] + \epsilon_t \]
where $\epsilon_t \sim N(0,\sigma^2)$. \pause If $\theta_{t-1} \sim N(\mu,\sigma^2/[1-\rho^2])$, then 
\[ \begin{array}{rl}
E[\theta^t] &= \mu \\
V[\theta^t] &= \rho^2 \frac{\sigma^2}{1-\rho^2} + \sigma^2 = \sigma^2
\end{array} \]
Thus $\theta^t \sim N(\mu,\sigma^2/[1-\rho^2])$ is the stationary distribution for an AR1 process.
\end{frame}

\begin{frame}[fragile]
\frametitle{Approximate via simulation}
<<ar1_stationary_distribution, fig.width=10>>=
mu = 10; sigma = 4; rho = 0.9
d = rdply(1000, function(x) {
  x = rcauchy(1) # initial draw (clearly not from stationary distribution)
  for (i in 1:100) x = rnorm(1,mu+rho*(x-mu),sigma)
  data.frame(x=x)
})
ggplot(d, aes(x=x))+geom_histogram(aes(y=..density..), binwidth=1)+stat_function(fun = dnorm, arg = list(mean=mu,sd=sigma/sqrt(1-rho^2)),col=2,lwd=2)
@
\end{frame}
\end{comment}


\end{document}
