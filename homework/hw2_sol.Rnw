\documentclass[12pt]{article}
\usepackage{amsmath,amssymb,mathrsfs,fancyhdr,syntonly,lastpage,hyperref,enumitem,graphicx}

\hypersetup{colorlinks=true,urlcolor=black}

\topmargin      -1.5cm   % read Lamport p.163
\oddsidemargin  -0.04cm  % read Lamport p.163
\evensidemargin -0.04cm  % same as oddsidemargin but for left-hand pages
\textwidth      16.59cm
\textheight     23.94cm
\parskip         7.2pt   % sets spacing between paragraphs
\parindent         0pt   % sets leading space for paragraphs
\pagestyle{empty}        % Uncomment if don't want page numbers
\pagestyle{fancyplain}


\begin{document}
\lhead{Homework 2}
\chead{PSTAT 544 - Bayesian statistics}
\rhead{Page \thepage\ of \pageref{LastPage}}

This homework is due on Blackboard Learn by 8:00am on 30 Jan. There will be a total of 10 points available. 

\begin{enumerate}
\item Let $Y_i\stackrel{iid}{\sim} \mbox{Po}(\lambda)$ and $\lambda\sim Ga(1,1)$. Conduct a simulation study to study the posterior mean, median, and mode evaluated according to squared error, absolute error, and step loss via the following steps.
  \begin{enumerate}
  \item Simulate $N=1,000$ $\lambda$s from its prior.
  \item For each $\lambda$, simulate a data set of size $n=5$. 
  \item For each of these data sets, calculate the posterior mean, median, and mode. 
  \item For each estimator, calculate the mean squared error, mean absolute error, and mean step loss (with a tolerance of $\epsilon=0.01$), i.e. 
  \[ 
  \mbox{MSE} = \frac{1}{N}\sum_{i=1}^N (\hat{\lambda}_i - \lambda_i)^2 \quad 
  \mbox{MAE} = \frac{1}{N}\sum_{i=1}^N |\hat{\lambda}_i - \lambda_i| \quad
  \mbox{MstE} = \frac{1}{N} \sum_{i=1}^N 1-\mathrm{I}(\lambda_i-\epsilon < \hat{\lambda}_i < \lambda_i+\epsilon)
  \]
  where $\lambda_i$ is the true value used for that simulation and $\hat{\lambda}_i$ is an estimator of $\lambda_i$ based on the data in that simulation. You should use each estimator under each error. 
  \item Determine which estimator performed best under each of the different loss functions.
  \end{enumerate}
  
\paragraph{Solution:}

<<simulation>>=
library(plyr)
library(reshape2)
set.seed(1)

n.sims = 1000
n = 5
a = b = 1
lambda = rgamma(n.sims, a, b)

dat = adply(lambda, 1, function(x){
  data.frame(lambda=x, y=rpois(n, x))
})

sum = ddply(dat, .(X1), summarize,
            alpha = a + sum(y),
            beta = b + length(y))

sum$mean   = sum$alpha/sum$beta
sum$median = qgamma(.5, sum$alpha, sum$beta)
sum$mode   = (sum$alpha-1)/sum$beta
sum$lambda = lambda

e = 0.01
res = ddply(melt(sum, id.vars=c("X1","lambda","alpha","beta")), 
            .(variable), summarize,
            mse = mean((lambda-value)^2),
            abs = mean(abs(lambda-value)),
            ste = mean(abs(lambda-value)>e))
res
@
  
Based on these simulations results, the mean minimized the mean square error, the median minimized the absolute error, and the mode minimized the step error.   
  
\item Let $Y_i\stackrel{iid}{\sim} \mbox{Po}(\lambda)$. 
  \begin{enumerate}
  \item Derive Jeffreys prior for $\lambda$. Determine whether this prior is proper. 
  
  \paragraph{Solution:}
  
  Since the Poisson is an exponential family, we can use Casella \& Berger Lemma 7.3.11,
  \begin{align*}
  \mathcal{I}(\lambda) &= -E_{y|\lambda}\left[ \frac{\partial^2}{\partial \lambda^2} \log p(y|\lambda) \right] \\ 
  &= -E_{y|\lambda}\left[ \frac{\partial^2}{\partial \lambda^2} n\overline{y} \log(\lambda) -n\lambda - \log\left(\prod_{i=1}^n y_i! \right) \right] \\
  &= -E_{y|\lambda}\left[ \frac{\partial}{\partial \lambda} \frac{n\overline{y}}{\lambda}  -n\right] \\
  &= -E_{y|\lambda}\left[ -\frac{n\overline{y}}{\lambda^2}  \right] \\
  &=  \frac{n\lambda}{\lambda^2} \\
  &=  \frac{n}{\lambda}   \\
  \end{align*}
  So the Jeffreys prior is 
  \[ p(\lambda) \propto \sqrt{|n/\lambda|} = \lambda^{-1/2} \]
  Since $\int_0^\infty \lambda^{-1/2} d\lambda$ is not finite, this distribution is improper. 
  
  \item Derive the posterior under Jeffreys prior. Determine the conditions when this posterior is proper. 
  
  \paragraph{Solution:}
  
  The posterior is 
  \begin{align*}
  p(\lambda|y) &\propto p(y|\lambda)p(\lambda) \\
  &\propto \lambda^{n\overline{y}} e^{-n\lambda} \lambda^{-1/2} \\
  &= \lambda^{n\overline{y}+1/2-1} e^{-n\lambda} 
  \end{align*}
  So this is the kernel of a gamma distribution with shape $n\overline{y}+1/2$ and rate $n$. This will be proper whenever $n>0$, i.e. you have at least one observation. 
  
  \item For the data $y=(4, 4, 5, 8, 3)$, determine the posterior under Jeffreys prior and provide the following 95\% credible intervals: equal-tailed, lower one-sided, upper one-sided, and HPD.
  
  \paragraph{Solution:}
  
<<intevals>>=
y = c(4,4,5,8,3)
a = sum(y)+1/2
b = length(y)

# Equal-tailed
qgamma(c(.025,.975), a, b)

# Lower one-sided
qgamma(c(0,.95), a ,b)

# Upper one-sided
qgamma(c(.05,1), a, b)

# HPD
interval = function(h, a, b) {
  # Returns (l,u) such that p(l|y) = p(u|y) = h
  m = (a-1)/b
  l = uniroot(function(x) dgamma(x,a,b)-h, c(0,m))$root
  u = uniroot(function(x) dgamma(x,a,b)-h, c(m,1e6))$root
  return(c(l,u))
}
res = uniroot(function(x) diff(pgamma(interval(x,a,b),a,b))-0.95, c(0, dgamma((a-1)/b,a,b)))
interval(res$root, a, b)
@  
  
  \end{enumerate}



\end{enumerate}




\end{document}
