\documentclass[12pt]{article}
\usepackage{amsmath,amssymb,mathrsfs,fancyhdr,syntonly,lastpage,hyperref,enumitem,graphicx,verbatim}

\hypersetup{colorlinks=true,urlcolor=black}

\topmargin      -1.5cm   % read Lamport p.163
\oddsidemargin  -0.04cm  % read Lamport p.163
\evensidemargin -0.04cm  % same as oddsidemargin but for left-hand pages
\textwidth      16.59cm
\textheight     23.94cm
\parskip         7.2pt   % sets spacing between paragraphs
\parindent         0pt   % sets leading space for paragraphs
\pagestyle{empty}        % Uncomment if don't want page numbers
\pagestyle{fancyplain}



\begin{document}
\lhead{Homework 6}
\chead{STAT 544 - Bayesian statistics}
\rhead{Page \thepage\ of \pageref{LastPage}}

This homework is due on Blackboard Learn by 8:00am on 27 Feb 2014. There will be a total of 10 points available. 

In this homework, consider the ordinary linear regression model, i.e. $y\sim N(X\beta, \sigma^2 \mathrm{I})$, with the default prior $p(\beta,\sigma^2)\propto 1/\sigma^2$. 

\begin{enumerate}
\item Derive the posterior $p(\beta,\sigma|y)=p(\beta|\sigma^2,y)p(\sigma^2|y)$. 
  \begin{enumerate}
  \item Derive the conditional posterior for $\beta$, i.e. $p(\beta|\sigma^2,y)$.
  
\paragraph{Solution:}
  
Note that if $\beta\sim N(b,\sigma^2 B)$, then
\begin{align*} 
p(\beta) &\propto \exp\left(-\frac{1}{2}[\beta-b]^\top [\sigma^2 B]^{-1}[\beta-b] \right) \\
&\propto \exp\left(-\frac{1}{2\sigma^2}[\beta' B^{-1} \beta -2\beta' B^{-1}b] \right) 
\end{align*}
is the kernel of a multivariate normal. 

\begin{align*}
p(\beta|\sigma^2,y) &\propto p(y|\beta,\sigma^2)p(\beta,\sigma^2) \\
&\propto \exp\left( -\frac{1}{2\sigma^2} (y-X\beta)^\top(y-X\beta)\right) \\
&\propto \exp \left( -\frac{1}{2\sigma^2} [\beta^\top X^\top X \beta - 2\beta'X'y]\right) \\
&\propto \exp \left( -\frac{1}{2\sigma^2} [\beta^\top X^\top X \beta - 2\beta'[X^\top X][X^\top X]^{-1} X'y]\right) \\
\end{align*}
This is the kernel of multivariate normal with mean $b=[X^\top X]^{-1} X'y$ and covariance matrix $\sigma^2B=\sigma^2[X^\top X]^{-1}$.
  
  \item Derive the marginal posterior for $\sigma^2$, i.e. $p(\sigma^2|y)$.
  
\paragraph{Solution:}  
  
Note that if $\sigma^2 \sim \mbox{Inv-}\chi^2(v,s^2)$, then 
\[ p(\sigma^2) \propto (\sigma^2)^{-(v/2+1)e^{-vs^2/(2\sigma^2)}}.  \]
  
The marginal posterior of $\sigma^2$ is 

\begin{align*}
p(\sigma^2|y) &= \frac{p(\beta,\sigma^2|y)}{p(\beta|\sigma^2,y)} \propto \frac{p(y|\beta,\sigma^2)p(\beta,\sigma^2)}{p(\beta|\sigma^2,y)} = \frac{p(y|b,\sigma^2)p(b,\sigma^2)}{p(b|\sigma^2,y)} \\
&\propto \frac{|\sigma^2\mathrm{I}_n|^{-1/2}\exp\left( -\frac{1}{2\sigma^2} (y-Xb)^\top(y-Xb)\right) \frac{1}{\sigma^{2}}}{|\sigma^2\mathrm{I}_k|^{-1/2}\exp\left( -\frac{1}{2\sigma^2} (b-b)^\top B^{-1} (b-b)\right)} \\
&\propto (\sigma^2)^{-\frac{n-k}{2}-1} \exp\left( -\frac{1}{2\sigma^2} (n-k)\frac{1}{n-k}(y-Xb)^\top(y-Xb)\right)
\end{align*}
which is an Inv-$\chi^2(n-k,s^2)$ where $s^2 = \frac{1}{n-k}(y-Xb)^\top(y-Xb)$ and $b$ is the mean from part a).
  
  \end{enumerate}
  
\item For $\tilde{y} \sim N(\tilde{X}\beta,\sigma^2\mathrm{I})$ where $\tilde{X}$ is known, derive the posterior predictive distribution $p(\tilde{y}|y)$.
  \begin{enumerate}
  \item Derive the conditional posterior predictive distribution $p(\tilde{y}|\sigma^2,y)$.
  
\paragraph{Solution:}

Let $\tilde{y} = \tilde{X}\beta + \tilde{\epsilon}$ with $\beta|\sigma^2,y\sim N(b,\sigma^2B)$ and, independently, $\tilde{\epsilon}|\sigma^2,y\sim N(0,\sigma^2\mathrm{I})$. Thus $\tilde{y}|\sigma^2,y$ is a linear combination of normals and therefore is normal with 
\begin{align*}
E[\tilde{y}|\sigma^2,y] &= \tilde{X}E[\beta|\sigma^2,y] = \tilde{X}b \\
V[\tilde{y}|\sigma^2,y] &= \tilde{X}Var[\beta|\sigma^2,y]\tilde{X}^\top + \sigma^2\mathrm{I} \\
&= \sigma^2\left[ \tilde{X}B\tilde{X}^\top +\mathrm{I} \right].
\end{align*}
  
  \item Use the result from 2b, to derive the posterior predictive distribution $p(\tilde{y}|y)$.
  
\paragraph{Solution:}

Since $\tilde{y}|\sigma^2,y$ is a normal distribution with mean $\tilde{X}b$ and variance $\sigma^2\left[ \tilde{X}B\tilde{X}^\top +\mathrm{I} \right]$ and $\sigma^2 \sim \mbox{Inv-}\chi^2(n-k,s^2)$, then $\tilde{y}|y \sim t_{n-k}(\tilde{X} b, s^2\left[ \tilde{X}B\tilde{X}^\top +\mathrm{I} \right])$, i.e. a t-distribution with $n-k$ degrees of freedom, location $\tilde{X}b$, and scale $s^2S=s^2\left[ \tilde{X}B\tilde{X}^\top +\mathrm{I} \right]$.

To prove this, note that if $\tilde{y}\sim t_v(p,P)$ then 
\[ p(\tilde{y}) \propto \left[1+\frac{1}{v} (\tilde{y}-p)^\top P^{-1}(\tilde{y}-p) \right]^{-(v+d)/2} \]
where $d$ is the dimension of $\tilde{y}$. 
{\small
\begin{align*}
p(\tilde{y}|y) &= \int p(\tilde{y}|\sigma^2,y)p(\sigma^2|y)d\sigma^2 \\
&\propto \int |\sigma^2 S|^{-1/2} \exp\left(-\frac{1}{2\sigma^2}(\tilde{y}-\tilde{X}b)^\top S^{-1}(\tilde{y}-\tilde{X}b)\right) (\sigma^2)^{-\frac{n-k}{2}-1} \exp\left( -\frac{1}{2\sigma^2} (n-k)s^2\right) d\sigma^2 \\
&\propto \int (\sigma^2)^{-\frac{n-k+d}{2}-1} \exp\left(-\frac{1}{2\sigma^2}\left[(\tilde{y}-\tilde{X}b)^\top S^{-1}(\tilde{y}-\tilde{X}b)+(n-k)s^2\right]\right)   d\sigma^2 \\
&= \left[(\tilde{y}-\tilde{X}b)^\top S^{-1}(\tilde{y}-\tilde{X}b)+(n-k)s^2\right]^{-\frac{n-k+d}{2}} \qquad \mbox{integrand is the kernel of a gamma}\\
&\propto \left[1+\frac{1}{n-k}(\tilde{y}-\tilde{X}b)^\top [s^2S]^{-1}(\tilde{y}-\tilde{X}b)\right]^{-\frac{n-k+d}{2}} \\
\end{align*}
}
which is the kernel of the multivariate $t$ mentioned above.
  
  \end{enumerate}

\end{enumerate}

\end{document}
